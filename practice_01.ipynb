{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfHZoUUoRbqcvN++klYTBA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MKJJang/airflow/blob/master/practice_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze3KkD6JlacW",
        "outputId": "886d4805-db42-409e-cbe4-3b51c12e5173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_text_list:  ['나는', '최근', '파리', '여행을', '다녀왔다']\n"
          ]
        }
      ],
      "source": [
        "# 띄어쓰기 단위로 분리\n",
        "input_text = \"나는 최근 파리 여행을 다녀왔다\"\n",
        "input_text_list = input_text.split()\n",
        "print(\"input_text_list: \", input_text_list)\n",
        "# input_text_list:  ['나는', '최근', '파리', '여행을', '다녀왔다']\n",
        "\n",
        "# 토큰 -> 아이디 딕셔너리와 아이디 -> 토큰 딕셔너리 만들기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str2idx = {word:idx for idx, word  in enumerate(input_text_list)}\n",
        "idx2str = {idx:word for idx, word in enumerate(input_text_list)}\n",
        "print(\"str2idx: \", str2idx)\n",
        "print(\"idx2str: \", idx2str)\n",
        "\n",
        "# 토큰을 토큰 아이디로 변환\n",
        "input_ids = [str2idx[word] for word in input_text_list]\n",
        "print(\"input_ids: \", input_ids)\n",
        "\n",
        "# str2idx:  {'나는': 0, '최근': 1, '파리': 2, '여행을': 3, '다녀왔다': 4}\n",
        "# idx2str:  {0: '나는', 1: '최근', 2: '파리', 3: '여행을', 4: '다녀왔다'}\n",
        "# input_ids:  [0, 1, 2, 3, 4]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2HsN87pmInw",
        "outputId": "079ba1fa-3598-4c2d-bd22-716635fd8c2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "str2idx:  {'나는': 0, '최근': 1, '파리': 2, '여행을': 3, '다녀왔다': 4}\n",
            "idx2str:  {0: '나는', 1: '최근', 2: '파리', 3: '여행을', 4: '다녀왔다'}\n",
            "input_ids:  [0, 1, 2, 3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "embedding_dim = 16\n",
        "embed_layer = nn.Embedding(len(str2idx), embedding_dim)"
      ],
      "metadata": {
        "id": "Aoom8xiCpjYK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "input_embeddings = embed_layer(torch.tensor(input_ids))\n",
        "input_embeddings = input_embeddings.unsqueeze(0)\n",
        "input_embeddings.shape\n",
        "input_embeddings = input_embeddings.unsqueeze(0)\n",
        "input_embeddings.shape\n",
        "\n",
        "# 1개의 문장이고 5개의 토큰이 있고 16차원의 임베딩이 생성되었음을 확인할 수 있다.\n",
        "# torch.Size([1, 1, 5, 16])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF_4fO0AmIqs",
        "outputId": "053c5098-b966-45e3-a557-8acb25d90ebd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 5, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_dim = 16\n",
        "max_position = 12\n",
        "embeded_layer = nn.Embedding(len(str2idx), embedding_dim)\n",
        "position_embed_layer = nn.Embedding(max_position, embedding_dim)\n",
        "\n",
        "position_ids = torch.arange(len(input_ids), dtype=torch.long).unsqueeze(0)\n",
        "position_encodings = position_embed_layer(position_ids)\n",
        "toked_embeddings = embed_layer(torch.tensor(input_ids)) # (5,16)\n",
        "token_embeddings = toked_embeddings.unsqueeze(0) # (1,5,16)\n",
        "token_embeddings = toked_embeddings + position_encodings\n",
        "input_embeddings.shape\n",
        "\n",
        "# torch.Size([1, 1, 5, 16])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P40RP4-ImItU",
        "outputId": "454c6aab-4842-4557-f454-fcfd0b38092d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 5, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yhglxxsKmIv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p68ZAdgYmIyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VDj3RnMKmI1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tmWsR0o9mI4B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}