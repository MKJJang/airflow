{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7/Xd0ynpqjM62uW9P/xTQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MKJJang/airflow/blob/master/03_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 허깅페이스 트랜스포머 활용에 필요한 라이브러리 설치\n",
        "!pip install transformers==4.40.1 datasets==2.19.0 huggingface_hub==0.23.0 -qqq"
      ],
      "metadata": {
        "id": "lSCm9HQQPfTG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3개 라이브러리(transformers, datasets, huggingface_hub) 설치 후 버전 확인\n",
        "#설치 완료 후, Huggging Face 관련 작업, 예를 들어 사전 훈련된 언어 모델을 활용한 작업을 수행할 수 있음.\n",
        "## transformers 토크나이저 활용할때 사용\n",
        "## datasets데이터셋 공개하고 쉽게 가져다 쓸 수 있도록 지원하여 트랜스포머 모델을 쉽게 학습하고 추론에 활용할 수 있도록 돕는다.\n",
        "import transformers\n",
        "import datasets\n",
        "import huggingface_hub\n",
        "\n",
        "print(transformers.__version__)\n",
        "print(datasets.__version__)\n",
        "print(huggingface_hub.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbQZYQiMPgL3",
        "outputId": "c51a542d-5a5e-4bd0-ae99-bccb0bd4080f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.40.1\n",
            "2.19.0\n",
            "0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 BERT와 GPT-2 모델을 활용할 때 허깅페이스 트랜스포머 코드 비교"
      ],
      "metadata": {
        "id": "VqsOoTMPUQV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "text = \"What is Huggingface Transformers?\"\n",
        "# BERT 모델 활용\n",
        "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "encoded_input = bert_tokenizer(text, return_tensors='pt')\n",
        "bert_output = bert_model(**encoded_input)\n",
        "\n",
        "# GPT-2 모델 활용\n",
        "gpt_model = AutoModel.from_pretrained('gpt2')\n",
        "gpt_tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "encoded_input = gpt_tokenizer(text, return_tensors='pt')\n",
        "gpt_output = gpt_model(**encoded_input)"
      ],
      "metadata": {
        "id": "DQyv0xp3PgTa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BERT Output Shape:\", bert_output.last_hidden_state.shape)  # BERT 출력 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8b2E8GEPgYf",
        "outputId": "0e1b12a1-a817-4f4c-89f6-fd1e22bc0ad3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Output Shape: torch.Size([1, 8, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 모델 아이디로 모델 불러오기 (모델 바디 불러오기)"
      ],
      "metadata": {
        "id": "ikm6bIOMmQau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "model_id = 'klue/roberta-base'  # RoBERTa 는 구글의 BERT를 개선한 모델이다.\n",
        "model = AutoModel.from_pretrained(model_id)\n",
        "\n",
        "# AutoModel 클래스는 어떻게 klue/roverta-base 저장소의 모델이 RoBERTa 계열의 모델인지 알 수 있을까?\n",
        "# 허깅페이스는 모델을 저장할 때 congif.json 파일이 함께 저장되는데, 해달 설정 파일에는 아래와 같이 모델 종류 및 파라미터, 클래스 등이 저장되어 확인할 수 있다.\n",
        "# 아래 3.3 AutoModel에 Model이 roberta로 되어 있고, AutoModel은 이 정보를 통해 RoBERTa 모델을 불러온다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v74T0DzPXiaY",
        "outputId": "00d211b6-20c2-4406-eb70-488f21b45c97"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.3 klue/robera-base 모델의 config.json 파일의 일부\n",
        "from transformers  import AutoConfig\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_id)\n",
        "print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fab3ORsoClL",
        "outputId": "35d90e49-f285-4c99-a604-fbe9c42c0278"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RobertaConfig {\n",
            "  \"_name_or_path\": \"klue/roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.40.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.4 모델 헤드가 포함된 모델 불러오기 (텍스트 분류 헤드가 붙어 있는 모델)"
      ],
      "metadata": {
        "id": "nLwqWbE5rH9b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YfLUzkH5oCn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k9IM5f7xoCtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uNKLXHKFoCvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "weTpSSvAoCyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jp7qegXuoC04"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}